# This docker-compose file is provided as an example to create a Docker Swarm based MSActivator setup
version: "3.8"

services:
  msa-front:
    image: openmsa/openmsa:msa2-front-2.8.0-f1aba7a929724e7d622bd3fb73ddfe38cdb5d9c8
    depends_on:
      - msa-api
      - msa-ui
      - camunda
      - msa-ai-ml
    healthcheck:
      test: ["CMD-SHELL", "curl -k --fail https://localhost"]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - "node.labels.manager==true"
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: ingress
      - target: 443
        published: 443
        protocol: tcp
        mode: ingress
      - target: 514
        published: 514
        protocol: udp
        mode: ingress
      - target: 162
        published: 162
        protocol: udp
        mode: ingress
      - target: 69
        published: 69
        protocol: udp
        mode: ingress
      - "5200-5200:5200-5200/udp"
    #
    # uncomment one of the 2 sections below when installing a custom certificate 
    # - Docker standard standalone installation
    #volumes:
    #    - "msa_front:/etc/nginx/ssl"
    # - Docker Swarm HA installation
    volumes:
        - "/mnt/NASVolume/msa_front/http_nginx.conf:/etc/nginx/conf.d/http_nginx.conf"
        - "/mnt/NASVolume/msa_front/privkey.pem:/etc/nginx/ssl/server.key"
        - "/mnt/NASVolume/msa_front/fullchain.pem:/etc/nginx/ssl/server.crt"
    
  msa-smtp:
    image: namshi/smtp
    environment:
      SMARTHOST_ADDRESS: smtp-relay.gmail.com
      SMARTHOST_PORT: 587
      MAILNAME: app.cloudclapp.com
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - "node.labels.manager==true"

  # PLAN B - NO BIG ANIMAL
  # db:
  #   image: ubiqube/msa2-db:4b77e929cc6238bc65dcfafb2e09edf0a0312559
  #   healthcheck:
  #     test: ["CMD-SHELL", "/usr/pgsql-12/bin/pg_isready -h localhost"]
  #     timeout: 20s
  #   environment:
  #     CAMUNDA_PASSWORD: camunda
  #     CAMUNDA_DB: process-engine
  #     CAMUNDA_USER: camunda
  #     KEY_VAULT_USER: key_vault
  #     KEY_VAULT_DB: key_vault
  #     PG_MODE: primary
  #     PG_PRIMARY_USER: postgres
  #     PG_PRIMARY_PASSWORD: my_db_password
  #     PG_USER: postgres
  #     PG_PASSWORD: my_db_password
  #     PG_DATABASE: POSTGRESQL
  #     PG_ROOT_PASSWORD: my_db_password
  #     PG_PRIMARY_PORT: 5432
  #     MAX_CONNECTIONS: 1600
  #   volumes:
  #     - "/mnt/NASVolume/msa_db:/pgsqldata/pgsql"
  #   deploy:
  #     replicas: 1
  #     placement:
  #       max_replicas_per_node: 1
  #       constraints:
  #         - "node.labels.manager==true"

  msa-api:
    image: openmsa/openmsa:msa2-api-2.8.0-775a94bdf0a3c943305aff4aef9af309b0e8d4ee
    # depends_on:
    #   - db
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8480"]
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
      - UBIQUBE_CAPTCHA_SECRET_KEY=6LcFwjQfAAAAAFQSLf1dKYPoGtmaLOwoCPSzGl5k
      - UBIQUBE_SUNCHRO=no
      - UBIQUBE_BYPASS_CAPTCHA=true
    volumes:
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/rrd_repository:/opt/rrd"
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/msa_api_logs:/opt/wildfly/logs/processLog"
      - "/mnt/NASVolume/msa_api_keystore:/etc/pki/jentreprise"
    networks:
      default:
        aliases:
          - "msa_api"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - "node.labels.worker==apps"
    extra_hosts:
      db: 20.223.38.173
#      msa-es: ES_IP

  msa-ui:
    image: openmsa/openmsa:msa2-ui-2.8.0-7affa55a1bfd61b50ad49bf37cb92dd6481a346a
    depends_on:
      - msa-api
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080"]
    environment:
    - FEATURE_ADMIN=true
    - FEATURE_CONNECTION_STATUS=true
    - FEATURE_ALARMS=true
    - FEATURE_LICENCE=true
    - FEATURE_TOPOLOGY=true
    - FEATURE_MONITORING_PROFILES=true
    - FEATURE_SCHEDULE_WORKFLOWS=true
    - FEATURE_PROFILE_AUDIT_LOGS=true
    - FEATURE_PERMISSION_PROFILES=true
    - FEATURE_AI_ML=true
    - FEATURE_WORKFLOW_OWNER=false
    networks:
      default:
        aliases:
          - "msa_ui"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.worker==apps"

  cloudclapp:
    depends_on:
      - msa-api
    image: ubiqube/cloudclapp:2eac4be3d24c6a5fbaa3590983a8d34fb3aa0caa
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080"]
    environment:
      - UBIQUBE_CAPTCHA_SITE_KEY=6LcFwjQfAAAAAICJb7KjGjfKay4O3sOPaOb0glie
      - UBIQUBE_LICENSE_AGREEMENT_LINK=https:\/\/cloudclapp.com\/EndUserLicenceAgreement.html
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.worker==apps"

  ccla-scan-app:
    image: ubiqube/cloudclapp-scan:d542e628d77781003a5b1970084df4ca4239e990
    environment:
      - UBIQUBE_ZAP_TOKEN=7da091fe-63a4-48c0-9bfa-7614c49feb7c
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"

  ccla-scan-env:
    image: owasp/zap2docker-stable
    entrypoint:
      - zap.sh
      - -daemon
      - -host
      - 0.0.0.0
      - -config
      - api.addrs.addr.name=.*
      - -config
      - api.addrs.addr.regex=true
      - -config
      - api.key=7da091fe-63a4-48c0-9bfa-7614c49feb7c
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"

  msa-sms:
    image: openmsa/openmsa:msa2-sms-2.8.0-1d2950f5d7fe546d9c4178ed6b6b79528713c816
    # depends_on:
    #   - db
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-sms status | grep -q 'service seems UP' || exit 1"]
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
      - CONTAINER_DOCKNAME={{.Task.Name}}.{{.Node.Hostname}}
    hostname: "{{.Task.Name}}.{{.Node.Hostname}}"
    volumes:
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/rrd_repository:/opt/rrd"
      - "/mnt/NASVolume/msa_svn:/opt/svnroot"
      - "/mnt/NASVolume/msa_bulkfiles:/opt/sms/spool/parser"
      - "/mnt/NASVolume/msa_sms_logs:/opt/sms/logs"
    networks:
      default:
        aliases:
          - "msa_sms"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.worker==apps"
    extra_hosts:
      db: 20.223.38.173

  msa-bud:
    image: openmsa/openmsa:msa2-bud-2.8.0-3af00721f97b3c44d583a7b40cf912b392a392d2
    # depends_on:
    #   - db
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-bud status | grep -q 'service seems UP' || exit 1"]
    networks:
      default:
        aliases:
          - "msa_bud"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
    extra_hosts:
      db: 20.223.38.173

  msa-alarm:
    depends_on:
    #  - db
      - msa-api
    image: openmsa/openmsa:msa2-alarm-2.8.0-5e4d2061605bce583225c3fcccd193e8ee40f4f4
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-alarm status | grep -q 'service seems UP' || exit 1"]
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
      - CONTAINER_DOCKNAME={{.Task.Name}}.{{.Node.Hostname}}
    hostname: "{{.Task.Name}}.{{.Node.Hostname}}"
    volumes:
      - "/mnt/NASVolume/msa_sms_logs:/opt/sms/logs"
    networks:
      default:
        aliases:
          - "msa_alarm"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
    extra_hosts:
      db: 20.223.38.173

  msa-monitoring:
    image: openmsa/openmsa:msa2-monitoring-2.8.0-33c2f74c0d854affc0690c6ab282b1f64a30cae2
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-poll status | grep -q 'service seems UP' || exit 1"]
    depends_on:
    #  - db
      - msa-es
      - msa-dev
      - msa-api
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    volumes:
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/rrd_repository:/opt/rrd"
      - "/mnt/NASVolume/msa_bulkfiles:/opt/sms/spool/parser"
      - "/mnt/NASVolume/msa_sms_logs:/opt/sms/logs"
    networks:
      default:
        aliases:
          - "msa_monitoring"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
    extra_hosts:
      db: 20.223.38.173
#      msa-es: ES_IP

  camunda:
    # depends_on:
    #   - db
    image: openmsa/openmsa:msa2-camunda-2.8.0-507b2c9b8361821915c4bd9255bafb47ace89079
    environment:
      DB_DRIVER: org.postgresql.Driver
      DB_URL: 'jdbc:postgresql://db:5432/process-engine'
      DB_USERNAME: camunda
      DB_PASSWORD: camunda
      DB_VALIDATE_ON_BORROW: 'true'
      WAIT_FOR: 'db:5432'
      WAIT_FOR_TIMEOUT: 60
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
    extra_hosts:
      db: 20.223.38.173

  msa-es:
    image: openmsa/openmsa:msa2-es-2.8.0-6b191fca4d76383f04930565d90dbf58a051eed4
    healthcheck:
      test: ["CMD-SHELL", "test -f /home/install/init-done && curl -s -XGET -H 'Authorization: Basic c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc='  'http://localhost:9200/_cluster/health?pretty' | grep -q 'status.*green' || exit 1"]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s 
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    environment:
      - discovery.type=single-node
      - script.painless.regex.enabled=true
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms512m -Xmx1024m
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    volumes:
      - "/mnt/NASVolume/msa_es:/usr/share/elasticsearch/data"
    networks:
      default:
        aliases:
          - "msa_es"

  msa-kibana:
    image: openmsa/openmsa:msa2-kibana-2.8.0-49c1c422ad5559815d4f74568904a7214e788932
    depends_on:
      - msa-es
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_URL=http://msa_es:9200
      - ELASTICSEARCH_HOSTS=http://msa_es:9200
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    networks:
      default:
        aliases:
          - "msa_kibana"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
#    extra_hosts:
#      msa-es: ES_IP

  msa-ai-ml:
    image: openmsa/openmsa:msa2-ai-ml-2.8.0-63c7fab8c111b6cc85da049f45ebc6175a9b269a
    healthcheck:
      test: ["CMD-SHELL", "python /msa_proj/health_check.py"]
    ports:
      - "8000:8000"
    volumes:
      - "/mnt/NASVolume/msa_ai_ml_db:/msa_proj/database"
    networks:
      default:
        aliases:
          - "msa_ai_ml"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"

  msa-cerebro:
    image: openmsa/openmsa:msa2-cerebro-2.8.0-914750e000db1343d9972bfa6652da1efe4aa32f
    environment:
      AUTH_TYPE: basic
      BASIC_AUTH_USER: cerebro
      BASIC_AUTH_PWD: "N@X{M4tfw'5%)+35"
    entrypoint:
      - /opt/cerebro/bin/cerebro
      - -Dhosts.0.host=http://msa_es:9200
    depends_on:
      - msa_es
    ports:
      - "9000:9000"
    networks:
      default:
        aliases:
          - "msa_cerebro"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
#    extra_hosts:
#      msa-es: ES_IP

  msa-dev:
    image: openmsa/openmsa:msa2-linuxdev-2.8.0-60956823e130ba38d6135eeda109d59058ab2ae8
    depends_on:
      - msa-es
    volumes:
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/msa_svn:/opt/svnroot"
    networks:
      default:
        aliases:
          - "msa_dev"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.apps==true"
#    extra_hosts:
#      msa-es: ES_IP

  key-vault:
#    depends_on:
#      - db
    image: vault:latest
    ports:
      - "8200:8200"
    volumes:
      - /mnt/NASVolume/msa_key_vault/config.hcl:/vault/config/config.hcl
    environment:
      VAULT_ADDR: "http://0.0.0.0:8200"
    cap_add:
      - IPC_LOCK
    command: server
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
#        constraints:
#          - "node.labels.manager==true"
    extra_hosts:
      db: 20.223.38.173


networks:
  default:
    driver_opts:
      encrypted: "true"
